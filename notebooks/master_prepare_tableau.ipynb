{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Prepare Notebook\n",
    "\n",
    "Deze notebook wordt gebruikt om alle data uit de datasets in te laden en verder te verwerken, zodat deze klaar staat om modellen te trainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load public modules.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Get the home dir and username.\n",
    "HOME = Path.home()\n",
    "USERNAME = os.path.basename(HOME)\n",
    "\n",
    "# Set codebase path for old VAO.\n",
    "CODEBASE_PATH_OLD = os.path.join(HOME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_OLD)\n",
    "                \n",
    "# Set codebase path for new VAO.\n",
    "CODEBASE_PATH_NEW = os.path.join('/data', USERNAME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_NEW)\n",
    "\n",
    "# Set codebase path for wonen server.\n",
    "CODEBASE_PATH_WONEN = os.path.abspath('E:\\\\Jasmine\\\\woonfraude\\\\codebase')\n",
    "sys.path.insert(1, CODEBASE_PATH_WONEN)\n",
    "\n",
    "# Import own modules.\n",
    "from datasets import *\n",
    "from clean import *\n",
    "from extract_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables.\n",
    "FORCE_DOWNLOAD = False\n",
    "FORCE_DATASET_SPECIFIC_PREPROCESSING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Initialize dataset objects #\n",
    "##############################\n",
    "\n",
    "adresDataset = AdresDataset()\n",
    "zakenDataset = ZakenDataset()\n",
    "stadiaDataset = StadiaDataset()\n",
    "personenDataset = PersonenDataset()\n",
    "bagDataset = BagDataset()\n",
    "hotlineDataset = HotlineDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'download' of dataset 'adres' loaded!\n",
      "Saving version 'download_leegstand' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'hvv_dag_tek', 'max_vestig_dtm']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Starting download of dataset 'bwv_adres_periodes'...\n",
      "\n",
      "#### ...download done! Spent 6.33 seconds.\n",
      "\n",
      "Saving version 'download_leegstand_woningId' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'hvv_dag_tek', 'max_vestig_dtm']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'download' of dataset 'zaken' loaded!\n",
      "Lowered strings of cols ['beh_code', 'beh_oms', 'afg_code_beh', 'afs_code', 'afs_oms', 'afg_code_afs', 'eigenaar', 'zaak_id', 'mededelingen'] in df zaken!\n",
      "Dataframe \"zaken\": added column \"categorie\"!\n",
      "Saving version 'download_categories' of dataframe 'zaken'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['beh_code', 'beh_oms', 'afg_code_beh', 'afs_code', 'afs_oms', 'afg_code_afs', 'eigenaar', 'zaak_id', 'mededelingen', 'categorie']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving version 'download_categories_filterCategories' of dataframe 'zaken'.\n",
      "Version 'download' of dataset 'stadia' loaded!\n",
      "Saving version 'download_ids' of dataframe 'stadia'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'begindatum', 'peildatum', 'einddatum', 'date_created', 'date_modified', 'stadia_id', 'zaak_id', 'stadium_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered strings of cols ['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'begindatum', 'peildatum', 'einddatum', 'date_created', 'date_modified', 'stadia_id', 'zaak_id', 'stadium_id'] in df stadia!\n",
      "Dataframe \"stadia\": added column \"label\"!\n",
      "Saving version 'download_ids_labels' of dataframe 'stadia'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'stadia_id', 'zaak_id', 'stadium_id', 'label']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# Download data and perform dataset-specific pre-processing steps for dataset objects #\n",
    "#######################################################################################\n",
    "\n",
    "# Forces the downloading of new data.\n",
    "if FORCE_DOWNLOAD:\n",
    "    adresDataset.download(force=True)\n",
    "    zakenDataset.download(force=True)\n",
    "    stadiaDataset.download(force=True)\n",
    "    personenDataset.download(force=True)\n",
    "#     bagDataset.download(force=True)\n",
    "    hotlineDataset.download(force=True)\n",
    "    \n",
    "\n",
    " # Forces the dataset specific pre-processing of the downloaded data.\n",
    "if FORCE_DATASET_SPECIFIC_PREPROCESSING:\n",
    "    \n",
    "    # Adres dataset.\n",
    "    adresDataset.load('download')\n",
    "    adresDataset.extract_leegstand()\n",
    "    adresDataset.enrich_with_woning_id()\n",
    "\n",
    "    # Zaken Dataset.\n",
    "    zakenDataset.load('download')\n",
    "    zakenDataset.add_categories()\n",
    "    zakenDataset.filter_categories()  # Verwijder meldingen met categorieeen \"woningkwaliteit\" en \"afdeling vergunningen en beheer\".\n",
    "\n",
    "    # Stadia dataset.\n",
    "    stadiaDataset.load('download')\n",
    "    stadiaDataset.add_zaak_stadium_ids()\n",
    "    stadiaDataset.add_labels()\n",
    "\n",
    "    # Bag dataset.\n",
    "#     bagDataset.download(force=True)\n",
    "#     bagDataset.load('download')\n",
    "#     bagDataset.bag_fix()\n",
    "\n",
    "    # Hotline dataset.\n",
    "#     hotlineDataset.download(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'download_leegstand_woningId' of dataset 'adres' loaded!\n",
      "Version 'download_categories_filterCategories' of dataset 'zaken' loaded!\n",
      "Version 'download_ids_labels' of dataset 'stadia' loaded!\n",
      "Version 'download' of dataset 'personen' loaded!\n",
      "Version 'download_columnFix' of dataset 'bag' loaded!\n",
      "Version 'download' of dataset 'hotline' loaded!\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## Load datasets ##\n",
    "###################\n",
    "# Load datasets from cache (when download and pre-processing steps in previous block have been done).\n",
    "\n",
    "adresDataset.load('download_leegstand_woningId')\n",
    "zakenDataset.load('download_categories_filterCategories')\n",
    "stadiaDataset.load('download_ids_labels')\n",
    "personenDataset.load('download')\n",
    "bagDataset.load('download_columnFix')\n",
    "hotlineDataset.load('download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and extract features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"zaken\": Dropped 0 duplicates!\n",
      "Dataframe \"zaken\": Fixed dates!\n",
      "Dataframe \"zaken\": Cleaned out 4 dates!\n",
      "Lowered strings of cols ['beh_code', 'beh_oms', 'afg_code_beh', 'afs_code', 'afs_oms', 'afg_code_afs', 'eigenaar', 'zaak_id', 'mededelingen', 'categorie'] in df zaken!\n",
      "Missing values in df zaken have been imputed!\n",
      "Missing values (using custom strategy) of cols ['categorie'] in df zaken have been imputed!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Clean zaken dataset ##\n",
    "#########################\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=zakenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum','einddatum', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_custom={'categorie': 'missing'})\n",
    "    )])\n",
    "\n",
    "zaken = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"stadia\": Dropped 0 duplicates!\n",
      "Dataframe \"stadia\": Fixed dates!\n",
      "Dataframe \"stadia\": Cleaned out 0 dates!\n",
      "Lowered strings of cols ['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'stadia_id', 'zaak_id', 'stadium_id', 'label'] in df stadia!\n",
      "Missing values in df stadia have been imputed!\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Clean stadia dataset ##\n",
    "##########################\n",
    "\n",
    "stadiaPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=stadiaDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum', 'peildatum', 'einddatum', 'date_created',\n",
    "                          'date_modified', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "stadia = stadiaPipeline.fit_transform(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"personen\": Dropped 0 duplicates!\n",
      "Dataframe \"personen\": Fixed dates!\n",
      "Lowered strings of cols ['pen_type', 'gezinsverhouding', 'geslacht', 'voorletters', 'a_nr_gezinshoofd', 'a_nr', 'burgerlijke_staat', 'naam', 'geheim_adres', 'voorv_mnaam', 'voorv_naam', 'meisjesnaam', 'vertrekdatum_adam', 'ind_naamgebruik', 'nat_ned', 'ind_nat_ovlp', 'verblijfstatus', 'datum_einde_vblstat', 'landcode', 'user_created', 'user_modified', 'datum_begin_vblstat', 'ais_nr', 'crv_nr', 'geheim', 'anr_ouder_1', 'anr_ouder_2', 'anr_partner', 'in_onderzoek', 'datum_verkrijging_vreemd', 'voorletters_zdia', 'naam_zdia', 'voorv_mnaam_zdia', 'voorv_naam_zdia', 'meisjesnaam_zdia', 'nm_dia_255', 'mnm_dia_255'] in df personen!\n",
      "Missing values in df personen have been imputed!\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Clean personen dataset ##\n",
    "############################\n",
    "\n",
    "personenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=personenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['geboortedatum'],\n",
    "        lower_string_columns=True)\n",
    "    )])\n",
    "\n",
    "personen = personenPipeline.fit_transform(personenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"bag\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'postcode', 'type', 'adres_nummer', 'vervallen_nummeraanduiding', 'hoofdadres', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'vervallen_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'vervallen_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_mutatie', 'document_nummer', 'begin_geldigheid', 'einde_geldigheid'] in df bag!\n",
      "Missing values in df bag have been imputed!\n",
      "Missing values (using mode) of cols ['status_coordinaat_code'] in df bag have been imputed!\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "## Clean BAG dataset ##\n",
    "#######################\n",
    "\n",
    "bagPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=bagDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=[],\n",
    "        drop_columns = ['indicatie_geconstateerd', 'indicatie_in_onderzoek', 'woningvoorraad'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_mode=['status_coordinaat_code'],\n",
    "        fillna_columns={'_huisnummer_verblijfsobject': 0,\n",
    "                         '_huisletter_verblijfsobject': 'None',\n",
    "                         '_openbare_ruimte_naam_verblijfsobject': 'None',\n",
    "                         '_huisnummer_toevoeging_verblijfsobject': 'None',\n",
    "                         'type_woonobject_omschrijving': 'None',\n",
    "                         'eigendomsverhouding_id': 'None',\n",
    "                         'financieringswijze_id': -1,\n",
    "                         'gebruik_id': -1,\n",
    "                         'reden_opvoer_id': -1,\n",
    "                         'status_id_verblijfsobject': -1,\n",
    "                         'toegang_id': 'None'})\n",
    "    )])\n",
    "\n",
    "bagDataset.data = bagPipeline.fit_transform(bagDataset.data)\n",
    "bag = bagDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"hotline\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['mdw_code', 'overtreding_code', 'melder_anoniem', 'melder_naam', 'melder_emailadres', 'melder_telnr', 'situatie_schets', 'user_created', 'user_modified'] in df hotline!\n",
      "Missing values in df hotline have been imputed!\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Clean hotline dataset ##\n",
    "###########################\n",
    "\n",
    "hotlinePipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=hotlineDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "hotlineDataset.data = hotlinePipeline.fit_transform(hotlineDataset.data)\n",
    "hotline = hotlineDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"adres\": Dropped 0 duplicates!\n",
      "Dataframe \"adres\": Fixed dates!\n",
      "Lowered strings of cols ['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'hvv_dag_tek', 'max_vestig_dtm'] in df adres!\n",
      "Missing values in df adres have been imputed!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Clean adres dataset ##\n",
    "#########################\n",
    "\n",
    "# Hier de extract stap weghalen? Deze past waarschijnlijk beter na het combinen v/d datasets.\n",
    "adresPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=adresDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['hvv_dag_tek', 'max_vestig_dtm', 'wzs_update_datumtijd'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        fillna_columns={'hsnr': 0, 'sttnaam': 'None', 'hsltr': 'None', 'toev': 'None'})\n",
    "    )])\n",
    "\n",
    "adresDataset.data = adresPipeline.fit_transform(adresDataset.data)\n",
    "adres = adresDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df adres have been imputed!\n",
      "Saving version 'download_leegstand_woningId_bag' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_nummer']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adres dataset is now enriched with BAG data.\n",
      "Now looping over all address ids that have a link with one or more inhabitants...\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "Now looping over all rows in the adres dataframe in order to add person information...\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "...done!\n",
      "Saving version 'download_leegstand_woningId_bag_personen' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block6_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_nummer']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adres dataset is now enriched with personen data.\n",
      "Saving version 'download_leegstand_woningId_bag_personen_hotline' of dataframe 'adres'.\n",
      "The adres dataset is now enriched with hotline data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:183: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 18514 finished cases from a total of 34202 cases.\n",
      "Saving version 'download_categories_filterCategories_finishedCases' of dataframe 'zaken'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['afg_code_afs', 'afg_code_beh', 'afs_code', 'afs_oms', 'beh_code', 'beh_oms', 'categorie', 'eigenaar', 'mededelingen', 'zaak_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"zaken\": added column \"woonfraude\" (binary label)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Enrich adres dataset ##\n",
    "##########################\n",
    "\n",
    "# Enrich the adres dataset with information from the bag, personen and hotline datasets.\n",
    "adresDataset.enrich_with_bag(bagDataset.data)\n",
    "adresDataset.enrich_with_personen_features(personenDataset.data)\n",
    "adresDataset.add_hotline_features(hotlineDataset.data)\n",
    "\n",
    "\n",
    "##########################\n",
    "## Enrich zaken dataset ##\n",
    "##########################\n",
    "\n",
    "# Only keep the finished cases in the zaken dataset (remove all unfinished cases).\n",
    "# zakenDataset.keep_finished_cases(stadiaDataset.data)\n",
    "\n",
    "# Add a label to indicate woonfraude.\n",
    "# zakenDataset.add_binary_label_zaken(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Remove implicit label columns and superfluous columns  from adres dataset ##\n",
    "###############################################################################\n",
    "\n",
    "adres_remove = [# Remove because cols do not exists when melding is received\n",
    "                    'wzs_update_datumtijd',\n",
    "                    # Remove because cols do not add extra information.\n",
    "                    'kmrs',\n",
    "                    'straatcode',\n",
    "                    'xref',\n",
    "                    'yref',\n",
    "                    'postcode',\n",
    "                    'wzs_buurtcode_os_2015',\n",
    "                    'wzs_buurtcombinatiecode_os_2015',\n",
    "                    'wzs_stadsdeelcode_os_2015',\n",
    "                    'hvv_dag_tek', # Empty column\n",
    "                    'max_vestig_dtm', # Empty column\n",
    "                    'wzs_22gebiedencode_os_2015', # Empty column\n",
    "                    'wzs_22gebiedennaam_os_2015', # Empty column\n",
    "                    'pvh_cd',\n",
    "                    'sbv_code',\n",
    "                    'sbw_code',\n",
    "                    'wzs_wijze_verrijking_geo',\n",
    "                    'wzs_22gebiedencode_2015',\n",
    "                    'brt_naam',\n",
    "                    'wzs_buurtnaam_os_2015',\n",
    "                    'wzs_buurtcombinatienaam_os_2015',\n",
    "                    'wzs_rayonnaam_os_2015',\n",
    "                    'wzs_rayoncode_os_2015',\n",
    "                    'wzs_stadsdeelnaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtennaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtencode_os_2015',\n",
    "                    'wzs_geom',\n",
    "                    'brt_code',\n",
    "                    'brtcombi_code',\n",
    "                    'brtcombi_naam',\n",
    "                    'sdl_code',\n",
    "                    'wzs_22gebiedennaam_2015',\n",
    "                    'wzs_id',\n",
    "                    'a_dam_bag',\n",
    "                    'landelijk_bag']\n",
    "\n",
    "bag_remove = ['einde_geldigheid',               # Only 2 entries in column.\n",
    "              'verhuurbare_eenheden',           # Only ~2k entries in column.\n",
    "              'geometrie_ligplaats',            # Needs a lot of processing before being useful.\n",
    "              'bron_id_verblijfsobject',        # Only 2 entries in column.\n",
    "              'locatie_ingang_id',              # Only 2 entries in column.\n",
    "              'reden_afvoer_id',                # Only a few entries in column.\n",
    "              '_gebiedsgerichtwerken_id',       # Superfluous (gebied).\n",
    "              '_grootstedelijkgebied_id',       # Superfluous (grootstedelijkgebied).\n",
    "              'buurt_id',                       # Superfluous (buurt).\n",
    "              # ONDERSTAANDE 4 KOLOMMEN KONDEN EERDER NIET WEG IVM MATCH MET ADRES DATAFRAME.\n",
    "              # DEZE MOETEN NU WEL WEG, DAAROM WORDT NU HIER ALLES WEGGEHAALD.\n",
    "              '_openbare_ruimte_naam_nummeraanduiding',          # Superfluous (straatnaam).\n",
    "              'vervallen_nummeraanduiding',\n",
    "              'vervallen_ligplaats',\n",
    "              'vervallen_standplaats',\n",
    "              'vervallen_verblijfsobject',\n",
    "              'document_mutatie',               # Not available at time of signal.\n",
    "              'date_modified_nummeraanduiding', # Not available at time of signal.\n",
    "              'document_nummer',                # Not needed? (Swaan?)\n",
    "              'status_coordinaat_omschrijving', # Not needed? (Swaan?)\n",
    "              'type_woonobject_code',           # Not needed? (Swaan?)\n",
    "              'id_ligplaats',                   # Not needed.\n",
    "              'landelijk_id_ligplaats',         # Not needed.\n",
    "              'id_standplaats',                 # Not needed.\n",
    "              'landelijk_id_standplaats',       # Not needed.\n",
    "              'id_verblijfsobject',             # Not needed.\n",
    "              'landelijk_id_verblijfsobject',   # Not needed.\n",
    "              ]\n",
    "\n",
    "# Remove the columns that are defined above from the dataset.\n",
    "adresDataset.data.drop(columns=adres_remove + bag_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Merge the adres dataset onto the zaken dataset ##\n",
    "####################################################\n",
    "\n",
    "# Merge the adres dataset onto the zaken dataset.\n",
    "zakenDataset.data = zakenDataset.data.merge(adresDataset.data, on='adres_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now extracting features from column: 'afg_code_beh'.\n",
      "Done!\n",
      "Now extracting features from column: 'beh_code'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigenaar'.\n",
      "Done!\n",
      "Now extracting features from column: 'categorie'.\n",
      "Done!\n",
      "Now extracting features from column: 'toev'.\n",
      "Done!\n",
      "Now extracting features from column: 'pvh_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbw_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbv_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'status_coordinaat_code'.\n",
      "Done!\n",
      "Now extracting features from column: 'type_woonobject_omschrijving'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigendomsverhouding_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'financieringswijze_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'gebruik_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'ligging_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'reden_opvoer_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'status_id_nummeraanduiding'.\n",
      "Done!\n",
      "Now extracting features from column: 'toegang_id'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "## Perform feature extraction on zaken dataset ##\n",
    "#################################################\n",
    "\n",
    "categorical_col_hot_zaken = ['afg_code_beh', 'beh_code', 'eigenaar', 'categorie']\n",
    "categorical_cols_hot_adres = ['toev', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr']\n",
    "categorical_cols_hot_bag = ['status_coordinaat_code', 'type_woonobject_omschrijving',\n",
    "                            'eigendomsverhouding_id', 'financieringswijze_id',\n",
    "                            'gebruik_id', 'ligging_id', 'reden_opvoer_id',\n",
    "                            'status_id_nummeraanduiding', 'toegang_id']\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=categorical_col_hot_zaken + categorical_cols_hot_adres + categorical_cols_hot_bag,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "zakenDataset.data = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Finalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving version 'final' of dataframe 'zaken'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block6_values] [items->['afg_code_afs', 'afg_code_beh', 'afs_code', 'afs_oms', 'beh_code', 'beh_oms', 'categorie', 'eigenaar', 'mededelingen', 'zaak_id', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'sttnaam', 'hsltr', 'toev', 'sdl_naam', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'bron_id_ligplaats', 'status_id_ligplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'status_coordinaat_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Save.\n",
    "zakenDataset.version = 'final'\n",
    "zakenDataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
