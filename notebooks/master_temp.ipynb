{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pathlib import Path\n",
    "\n",
    "# Add local codebase to path\n",
    "home = str(Path.home())\n",
    "sys.path.insert(1, f'{home}/Documents/woonfraude/codebase')\n",
    "\n",
    "# Import own modules\n",
    "from datasets_oo import *\n",
    "from clean_oo import *\n",
    "from extract_features_oo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'download_leegstand_woningId' of dataset 'adres' loaded!\n",
      "Version 'download_categories_filterCategories' of dataset 'zaken' loaded!\n",
      "Version 'download_ids_labels' of dataset 'stadia' loaded!\n",
      "Version 'download' of dataset 'personen' loaded!\n",
      "Version 'download_columnFix' of dataset 'bag' loaded!\n",
      "Version 'download' of dataset 'hotline' loaded!\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## Load datasets ##\n",
    "###################\n",
    "# Download (or load cached versions of) the datasets.\n",
    "\n",
    "# Initialize dataset objects\n",
    "adresDataset = AdresDataset()\n",
    "zakenDataset = ZakenDataset()\n",
    "stadiaDataset = StadiaDataset()\n",
    "personenDataset = PersonenDataset()\n",
    "bagDataset = BagDataset()\n",
    "hotlineDataset = HotlineDataset()\n",
    "\n",
    "# # Download and perform dataset-specific processing.\n",
    "# # Uncomment code and run once. Use load-from cache functionality below afterwards.\n",
    "# adresDataset.download(force=True)\n",
    "# adresDataset.extract_leegstand()\n",
    "# adresDataset.enrich_with_woning_id()\n",
    "\n",
    "# zakenDataset.download(force=True)\n",
    "# zakenDataset.add_categories()\n",
    "# zakenDataset.filter_categories()\n",
    "\n",
    "# stadiaDataset.download(force=True)\n",
    "# stadiaDataset.add_zaak_stadium_ids()\n",
    "# stadiaDataset.add_labels()\n",
    "\n",
    "# personenDataset.download(force=True)\n",
    "\n",
    "# bagDataset.download(force=True)\n",
    "# bagDataset.bag_fix()\n",
    "\n",
    "# hotlineDataset.download(force=True)\n",
    "\n",
    "\n",
    "# Load datasets from cache (if download and processing steps have already been done).\n",
    "adresDataset.load('download_leegstand_woningId')\n",
    "zakenDataset.load('download_categories_filterCategories')\n",
    "stadiaDataset.load('download_ids_labels')\n",
    "personenDataset.load('download')\n",
    "bagDataset.load('download_columnFix')\n",
    "hotlineDataset.load('download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"zaken\": Dropped 0 duplicates!\n",
      "Dataframe \"zaken\": Fixed dates!\n",
      "Dataframe \"zaken\": Cleaned out 3 dates!\n",
      "Lowered strings of cols ['beh_code', 'beh_oms', 'afg_code_beh', 'afs_code', 'afs_oms', 'afg_code_afs', 'eigenaar', 'zaak_id', 'mededelingen', 'categorie'] in df zaken!\n",
      "Now extracting features from column: 'afg_code_beh'.\n",
      "Done!\n",
      "Now extracting features from column: 'beh_code'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigenaar'.\n",
      "Done!\n",
      "Now extracting features from column: 'categorie'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Clean zaken dataset ##\n",
    "#########################\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=zakenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum','einddatum', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    ),\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=['afg_code_beh', 'beh_code', 'eigenaar', 'categorie'])\n",
    "    )\n",
    "    ])\n",
    "\n",
    "zaken = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"stadia\": Dropped 0 duplicates!\n",
      "Dataframe \"stadia\": Fixed dates!\n",
      "Dataframe \"stadia\": Cleaned out 0 dates!\n",
      "Lowered strings of cols ['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'stadia_id', 'zaak_id', 'stadium_id', 'label'] in df stadia!\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Clean stadia dataset ##\n",
    "##########################\n",
    "\n",
    "stadiaPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=stadiaDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum', 'peildatum', 'einddatum', 'date_created',\n",
    "                          'date_modified', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "stadia = stadiaPipeline.fit_transform(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"personen\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['pen_type', 'gezinsverhouding', 'geslacht', 'voorletters', 'geboortedatum', 'burgerlijke_staat', 'naam', 'geheim_adres', 'voorv_mnaam', 'voorv_naam', 'meisjesnaam', 'vertrekdatum_adam', 'ind_naamgebruik', 'nat_ned', 'ind_nat_ovlp', 'verblijfstatus', 'datum_einde_vblstat', 'landcode', 'user_created', 'user_modified', 'datum_begin_vblstat', 'ais_nr', 'crv_nr', 'geheim', 'in_onderzoek', 'datum_verkrijging_vreemd', 'voorletters_zdia', 'naam_zdia', 'voorv_mnaam_zdia', 'voorv_naam_zdia', 'meisjesnaam_zdia', 'nm_dia_255', 'mnm_dia_255'] in df personen!\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Clean personen dataset ##\n",
    "############################\n",
    "\n",
    "personenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=personenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        lower_string_columns=True)\n",
    "    )])\n",
    "\n",
    "personen = personenPipeline.fit_transform(personenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"bag\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['document_mutatie@bag', 'document_nummer@bag', 'begin_geldigheid@bag', 'einde_geldigheid@bag', 'id_nummeraanduiding@bag', 'landelijk_id_nummeraanduiding@bag', 'huisnummer_toevoeging@bag', 'postcode@bag', 'type@bag', 'adres_nummer@bag', 'vervallen@bag', 'hoofdadres@bag', '_openbare_ruimte_naam_nummeraanduiding@bag', 'bron_id@bag', 'ligplaats_id@bag', 'openbare_ruimte_id@bag', 'standplaats_id@bag', 'status_id_nummeraanduiding@bag', 'verblijfsobject_id@bag', '_geom@bag', 'id_ligplaats@bag', 'landelijk_id_ligplaats@bag', 'vervallen_1@bag', '_huisletter@bag', '_gebiedsgerichtwerken_id@bag', '_grootstedelijkgebied_id@bag', 'bron_id_1@bag', 'buurt_id@bag', 'status_id_ligplaats@bag', 'id_standplaats@bag', 'landelijk_id_standplaats@bag', 'vervallen_2@bag', 'bron_id_2@bag', 'status_id_standplaats@bag', 'id_verblijfsobject@bag', 'landelijk_id_verblijfsobject@bag', 'status_coordinaat_code@bag', 'status_coordinaat_omschrijving@bag', 'type_woonobject_code@bag', 'type_woonobject_omschrijving@bag', 'geometrie_2@bag', '_openbare_ruimte_naam_verblijfsobject@bag', '_huisletter_2@bag', '_huisnummer_toevoeging_2@bag', 'bron_id_3@bag', 'eigendomsverhouding_id@bag', 'financieringswijze_id@bag', 'gebruik_id@bag', 'ligging_id@bag', 'locatie_ingang_id@bag', 'reden_afvoer_id@bag', 'reden_opvoer_id@bag', 'status_id_verblijfsobject@bag', 'toegang_id@bag'] in df bag!\n",
      "Now extracting features from column: 'status_coordinaat_code@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'type_woonobject_omschrijving@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigendomsverhouding_id@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'financieringswijze_id@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'gebruik_id@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'ligging_id@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'reden_opvoer_id@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'status_id_nummeraanduiding@bag'.\n",
      "Done!\n",
      "Now extracting features from column: 'toegang_id@bag'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "## Clean BAG dataset ##\n",
    "#######################\n",
    "\n",
    "bagPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=bagDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=[],\n",
    "        drop_columns = ['indicatie_geconstateerd@bag', 'indicatie_in_onderzoek@bag', 'woningvoorraad@bag'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_mode=['status_coordinaat_code@bag'],\n",
    "#         impute_missing_values_mode=['status_coordinaat_code@bag', 'indicatie_geconstateerd@bag',\n",
    "#                                     'indicatie_in_onderzoek@bag', 'woningvoorraad@bag'],\n",
    "        fillna_columns={'_huisnummer@bag': 0,\n",
    "                         '_huisletter@bag': 'None',\n",
    "                         '_openbare_ruimte_naam_verblijfsobject@bag': 'None',\n",
    "                         '_huisnummer_toevoeging@bag': 'None',\n",
    "                         'type_woonobject_omschrijving@bag': 'None',\n",
    "                         'eigendomsverhouding_id@bag': 'None',\n",
    "                         'financieringswijze_id@bag': -1,\n",
    "                         'gebruik_id_nummeraanduiding@bag': -1,\n",
    "                         'reden_opvoer_id@bag': -1,\n",
    "                         'status_id_nummeraanduiding@bag': -1,\n",
    "                         'toegang_id@bag': 'None'})\n",
    "    ),\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=['status_coordinaat_code@bag', 'type_woonobject_omschrijving@bag',\n",
    "                              'eigendomsverhouding_id@bag', 'financieringswijze_id@bag',\n",
    "                              'gebruik_id@bag', 'ligging_id@bag', 'reden_opvoer_id@bag',\n",
    "                              'status_id_nummeraanduiding@bag', 'toegang_id@bag'])\n",
    "    )\n",
    "    ])\n",
    "\n",
    "bag = bagPipeline.fit_transform(bagDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"hotline\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['mdw_code', 'overtreding_code', 'melder_anoniem', 'melder_naam', 'melder_emailadres', 'melder_telnr', 'situatie_schets', 'user_created', 'user_modified'] in df hotline!\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Clean hotline dataset ##\n",
    "###########################\n",
    "\n",
    "hotlinePipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=hotlineDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "hotline = hotlinePipeline.fit_transform(hotlineDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"adres\": Dropped 0 duplicates!\n",
      "Dataframe \"adres\": Fixed dates!\n",
      "Lowered strings of cols ['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'hvv_dag_tek', 'max_vestig_dtm'] in df adres!\n",
      "Now extracting features from column: 'toev'.\n",
      "Done!\n",
      "Now extracting features from column: 'pvh_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbw_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbv_omschr'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Clean adres dataset ##\n",
    "#########################\n",
    "\n",
    "# Hier de extract stap weghalen? Deze past waarschijnlijk beter na het combinen v/d datasets.\n",
    "adresPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=adresDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['hvv_dag_tek', 'max_vestig_dtm', 'wzs_update_datumtijd'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        fillna_columns={'hsnr': 0, 'sttnaam': 'None', 'hsltr': 'None', 'toev': 'None'})\n",
    "    ),\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=['toev', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr'],\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "adres = adresPipeline.fit_transform(adresDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving version 'download_leegstand_woningId_bag' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/generic.py:2378: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block5_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'document_nummer@bag', 'id_nummeraanduiding@bag', 'landelijk_id_nummeraanduiding@bag', 'huisnummer_toevoeging@bag', 'postcode@bag', 'type@bag', 'adres_nummer@bag', '_openbare_ruimte_naam_nummeraanduiding@bag', 'bron_id@bag', 'ligplaats_id@bag', 'openbare_ruimte_id@bag', 'standplaats_id@bag', 'status_id_nummeraanduiding@bag', 'verblijfsobject_id@bag', '_geom@bag', 'id_ligplaats@bag', 'landelijk_id_ligplaats@bag', '_huisletter@bag', '_gebiedsgerichtwerken_id@bag', '_grootstedelijkgebied_id@bag', 'bron_id_1@bag', 'buurt_id@bag', 'status_id_ligplaats@bag', 'id_standplaats@bag', 'landelijk_id_standplaats@bag', 'bron_id_2@bag', 'status_id_standplaats@bag', 'id_verblijfsobject@bag', 'landelijk_id_verblijfsobject@bag', 'status_coordinaat_code@bag', 'status_coordinaat_omschrijving@bag', 'type_woonobject_code@bag', 'type_woonobject_omschrijving@bag', 'geometrie_2@bag', '_openbare_ruimte_naam_verblijfsobject@bag', '_huisletter_2@bag', '_huisnummer_toevoeging_2@bag', 'bron_id_3@bag', 'eigendomsverhouding_id@bag', 'ligging_id@bag', 'locatie_ingang_id@bag', 'reden_afvoer_id@bag', 'status_id_verblijfsobject@bag', 'toegang_id@bag']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4374\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4375\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c8cfa1676ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0madresDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menrich_with_bag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0madresDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menrich_with_personen_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonenDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0madresDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hotline_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotlineDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/woonfraude/codebase/datasets_oo.py\u001b[0m in \u001b[0;36menrich_with_personen_features\u001b[0;34m(self, personen)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mpersonen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geboortedatum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geboortedatum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# Get the most frequent birthdate (mode).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mgeboortedatum_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersonen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geboortedatum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Compute the age (result is a TimeDelta).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mpersonen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leeftijd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpersonen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geboortedatum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4382\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## Combine datasets ##\n",
    "######################\n",
    "\n",
    "adresDataset.enrich_with_bag(bagDataset.data)\n",
    "adresDataset.enrich_with_personen_features(personenDataset.data)\n",
    "adresDataset.add_hotline_features(hotlineDataset.data)\n",
    "\n",
    "adres_remove = [# Remove because cols do not exists when melding is received\n",
    "                    'wzs_update_datumtijd',\n",
    "                    # Remove because cols do not add extra information.\n",
    "                    'kmrs',\n",
    "                    'straatcode',\n",
    "                    'xref',\n",
    "                    'yref',\n",
    "                    'postcode',\n",
    "                    'wzs_buurtcode_os_2015',\n",
    "                    'wzs_buurtcombinatiecode_os_2015',\n",
    "                    'wzs_stadsdeelcode_os_2015',\n",
    "                    'sttnaam',\n",
    "                    'hvv_dag_tek', # Empty column\n",
    "                    'max_vestig_dtm', # Empty column\n",
    "                    'wzs_22gebiedencode_os_2015', # Empty column\n",
    "                    'wzs_22gebiedennaam_os_2015', # Empty column\n",
    "                    'sdl_naam',\n",
    "                    'pvh_cd',\n",
    "                    'sbv_code',\n",
    "                    'sbw_code',\n",
    "                    'wzs_wijze_verrijking_geo',\n",
    "                    'wzs_22gebiedencode_2015',\n",
    "                    'brt_naam',\n",
    "                    'wzs_buurtnaam_os_2015',\n",
    "                    'wzs_buurtcombinatienaam_os_2015',\n",
    "                    'wzs_rayonnaam_os_2015',\n",
    "                    'wzs_rayoncode_os_2015',\n",
    "                    'wzs_stadsdeelnaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtennaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtencode_os_2015',\n",
    "                    'hsltr',\n",
    "                    'wzs_geom',\n",
    "                    'brt_code',\n",
    "                    'brtcombi_code',\n",
    "                    'brtcombi_naam',\n",
    "                    'sdl_code',\n",
    "                    'wzs_22gebiedennaam_2015',\n",
    "                    'wzs_id',\n",
    "                    'a_dam_bag',\n",
    "                    'landelijk_bag']\n",
    "\n",
    "bag_remove = ['einde_geldigheid@bag',               # Only 2 entries in column.\n",
    "              'verhuurbare_eenheden@bag',           # Only ~2k entries in column.\n",
    "              'geometrie@bag',                      # Needs a lot of processing before being useful.\n",
    "              'bron_id@bag',                        # Only 2 entries in column.\n",
    "              'locatie_ingang_id@bag',              # Only 2 entries in column.\n",
    "              'reden_afvoer_id@bag',                # Only a few entries in column.\n",
    "              '_gebiedsgerichtwerken_id@bag',       # Superfluous (gebied).\n",
    "              '_grootstedelijkgebied_id@bag',       # Superfluous (grootstedelijkgebied).\n",
    "              'buurt_id@bag',                       # Superfluous (buurt).\n",
    "              # ONDERSTAANDE 4 KOLOMMEN KONDEN EERDER NIET WEG IVM MATCH MET ADRES DATAFRAME.\n",
    "              # DEZE MOETEN NU WEL WEG, DAAROM WORDT NU HIER ALLES WEGGEHAALD.\n",
    "              '_openbare_ruimte_naam_verblijfsobject@bag',          # Superfluous (straatnaam).\n",
    "              '_huisnummer@bag',                    # Superfluous (huisnummer).\n",
    "              '_huisletter@bag',                    # Superfluous (huisletter).\n",
    "              '_huisnummer_toevoeging@bag',         # Superfluous (huisnummer toevoeging).\n",
    "              'vervallen@bag',                      # Superfluous (all values in col are equal).\n",
    "              'mutatie_gebruiker@bag',              # Superfluous (all values in col are equal).\n",
    "              'document_mutatie@bag',               # Not available at time of signal.\n",
    "              'date_modified@bag',                  # Not available at time of signal.\n",
    "              'document_nummer@bag',                # Not needed? (Swaan?)\n",
    "              'status_coordinaat_omschrijving@bag', # Not needed? (Swaan?)\n",
    "              'type_woonobject_code@bag',           # Not needed? (Swaan?)\n",
    "              'id@bag',                             # Not needed.\n",
    "              'landelijk_id@bag'                    # Not needed.\n",
    "              ]\n",
    "\n",
    "# Remove adres_id, since this is not a feature we want our algorihtm to try and learn from.\n",
    "adresDataset.data.drop(columns=adres_remove + bag_remove + ['adres_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagDataset.data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagDataset.data['status_coordinaat_code@bag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaT\n",
       "1         NaT\n",
       "2         NaT\n",
       "3         NaT\n",
       "4         NaT\n",
       "5         NaT\n",
       "6         NaT\n",
       "7         NaT\n",
       "8         NaT\n",
       "9         NaT\n",
       "10        NaT\n",
       "11        NaT\n",
       "12        NaT\n",
       "13        NaT\n",
       "14        NaT\n",
       "15        NaT\n",
       "16        NaT\n",
       "17        NaT\n",
       "18        NaT\n",
       "19        NaT\n",
       "20        NaT\n",
       "21        NaT\n",
       "22        NaT\n",
       "23        NaT\n",
       "24        NaT\n",
       "25        NaT\n",
       "26        NaT\n",
       "27        NaT\n",
       "28        NaT\n",
       "29        NaT\n",
       "           ..\n",
       "1886171   NaT\n",
       "1886172   NaT\n",
       "1886173   NaT\n",
       "1886174   NaT\n",
       "1886175   NaT\n",
       "1886176   NaT\n",
       "1886177   NaT\n",
       "1886178   NaT\n",
       "1886179   NaT\n",
       "1886180   NaT\n",
       "1886181   NaT\n",
       "1886182   NaT\n",
       "1886183   NaT\n",
       "1886184   NaT\n",
       "1886185   NaT\n",
       "1886186   NaT\n",
       "1886187   NaT\n",
       "1886188   NaT\n",
       "1886189   NaT\n",
       "1886190   NaT\n",
       "1886191   NaT\n",
       "1886192   NaT\n",
       "1886193   NaT\n",
       "1886194   NaT\n",
       "1886195   NaT\n",
       "1886196   NaT\n",
       "1886197   NaT\n",
       "1886198   NaT\n",
       "1886199   NaT\n",
       "1886200   NaT\n",
       "Name: geboortedatum, Length: 1886201, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personenDataset.data['geboortedatum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
