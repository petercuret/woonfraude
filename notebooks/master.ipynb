{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- [x] UPDATEN VAN DE bag_remove KOLOMMEN\n",
    "- [x] BASE NOTEBOOK UPDATEN & MASTER NOTEBOOK HIERIN AANROEPEN (PAPERMILL)\n",
    "- [x] MACHINE LEARNING WEER LATEN WERKEN\n",
    "- [x] DOCUMENTEREN NOTEBOOKS\n",
    "- [ ] DOCUMENTEREN README\n",
    "- [ ] RandomForestRegressor gebruiken ipv RandomForestClassifier (heeft andere evaluation metric nodig, of ergens instellen dat 50+% confidence == True, en 50-% confidence == False.\n",
    "- [ ] Checken of droppen van text kolommen uit zaken df, net voorafgaand aan de train/test set creation, okay is. \n",
    "- [ ] PARAMETER OPTIMALISATIE SEARCH RUNNEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load public modules.\n",
    "import os, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Get the home dir and username.\n",
    "HOME = Path.home()\n",
    "USERNAME = os.path.basename(HOME)\n",
    "\n",
    "# Set codebase path for old VAO.\n",
    "CODEBASE_PATH_OLD = os.path.join(HOME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_OLD)\n",
    "                \n",
    "# Set codebase path for new VAO.\n",
    "CODEBASE_PATH_NEW = os.path.join('/data', USERNAME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_NEW)\n",
    "\n",
    "# Import own modules.\n",
    "from datasets_oo import *\n",
    "from clean_oo import *\n",
    "from build_model import *\n",
    "from extract_features_oo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables.\n",
    "FORCE_DOWNLOAD = False\n",
    "FORCE_DATASET_SPECIFIC_PREPROCESSING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Initialize dataset objects #\n",
    "##############################\n",
    "\n",
    "adresDataset = AdresDataset()\n",
    "zakenDataset = ZakenDataset()\n",
    "stadiaDataset = StadiaDataset()\n",
    "personenDataset = PersonenDataset()\n",
    "bagDataset = BagDataset()\n",
    "hotlineDataset = HotlineDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Download data and perform dataset-specific pre-processing steps for dataset objects #\n",
    "#######################################################################################\n",
    "\n",
    "# Forces the downloading of new data.\n",
    "if FORCE_DOWNLOAD:\n",
    "    adresDataset.download(force=True)\n",
    "    zakenDataset.download(force=True)\n",
    "    stadiaDataset.download(force=True)\n",
    "    personenDataset.download(force=True)\n",
    "    bagDataset.download(force=True)\n",
    "    \n",
    "\n",
    " # Forces the dataset specific pre-processing of the downloaded data.\n",
    "if FORCE_DATASET_SPECIFIC_PREPROCESSING:\n",
    "    \n",
    "    # Adres dataset.\n",
    "    adresDataset.load('download')\n",
    "    adresDataset.extract_leegstand()\n",
    "    adresDataset.enrich_with_woning_id()\n",
    "\n",
    "    # Zaken Dataset.\n",
    "    zakenDataset.load('download')\n",
    "    zakenDataset.add_categories()\n",
    "    zakenDataset.filter_categories()  # Verwijder meldingen met categorieeen \"woningkwaliteit\" en \"afdeling vergunningen en beheer\".\n",
    "\n",
    "    # Stadia dataset.\n",
    "    stadiaDataset.load('download')\n",
    "    stadiaDataset.add_zaak_stadium_ids()\n",
    "    stadiaDataset.add_labels()\n",
    "\n",
    "    # Bag dataset.\n",
    "    bagDataset.download(force=True)\n",
    "    bagDataset.load('download')\n",
    "    bagDataset.bag_fix()\n",
    "\n",
    "    # Hotline dataset.\n",
    "    hotlineDataset.download(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'download_leegstand_woningId' of dataset 'adres' loaded!\n",
      "Version 'download_categories_filterCategories' of dataset 'zaken' loaded!\n",
      "Version 'download_ids_labels' of dataset 'stadia' loaded!\n",
      "Version 'download' of dataset 'personen' loaded!\n",
      "Version 'download_columnFix' of dataset 'bag' loaded!\n",
      "Version 'download' of dataset 'hotline' loaded!\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## Load datasets ##\n",
    "###################\n",
    "# Load datasets from cache (when download and pre-processing steps in previous block have been done).\n",
    "\n",
    "adresDataset.load('download_leegstand_woningId')\n",
    "zakenDataset.load('download_categories_filterCategories')\n",
    "stadiaDataset.load('download_ids_labels')\n",
    "personenDataset.load('download')\n",
    "bagDataset.load('download_columnFix')\n",
    "hotlineDataset.load('download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and extract features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"zaken\": Dropped 0 duplicates!\n",
      "Dataframe \"zaken\": Fixed dates!\n",
      "Dataframe \"zaken\": Cleaned out 3 dates!\n",
      "Lowered strings of cols ['beh_code', 'beh_oms', 'afg_code_beh', 'afs_code', 'afs_oms', 'afg_code_afs', 'eigenaar', 'zaak_id', 'mededelingen', 'categorie'] in df zaken!\n",
      "Missing values in df zaken have been imputed!\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## Clean zaken dataset & perform feature extraction ##\n",
    "######################################################\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=zakenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum','einddatum', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    ),\n",
    "#     ('extract', FeatureExtractionTransformer(\n",
    "#         categorical_cols_hot=['afg_code_beh', 'beh_code', 'eigenaar', 'categorie'])\n",
    "#     )\n",
    "    ])\n",
    "\n",
    "zaken = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"stadia\": Dropped 0 duplicates!\n",
      "Dataframe \"stadia\": Fixed dates!\n",
      "Dataframe \"stadia\": Cleaned out 0 dates!\n",
      "Lowered strings of cols ['afg_co', 'sta_code', 'sta_oms', 'afg_code_stad', 'afs_code', 'afs_oms', 'afg_code_afs', 'resultaat', 'mdr_code', 'user_created', 'user_modified', 'stadia_id', 'zaak_id', 'stadium_id', 'label'] in df stadia!\n",
      "Missing values in df stadia have been imputed!\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Clean stadia dataset ##\n",
    "##########################\n",
    "\n",
    "stadiaPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=stadiaDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum', 'peildatum', 'einddatum', 'date_created',\n",
    "                          'date_modified', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "stadia = stadiaPipeline.fit_transform(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"personen\": Dropped 0 duplicates!\n",
      "Dataframe \"personen\": Fixed dates!\n",
      "Lowered strings of cols ['pen_type', 'gezinsverhouding', 'geslacht', 'voorletters', 'burgerlijke_staat', 'naam', 'geheim_adres', 'voorv_mnaam', 'voorv_naam', 'meisjesnaam', 'vertrekdatum_adam', 'ind_naamgebruik', 'nat_ned', 'ind_nat_ovlp', 'verblijfstatus', 'datum_einde_vblstat', 'landcode', 'user_created', 'user_modified', 'datum_begin_vblstat', 'ais_nr', 'crv_nr', 'geheim', 'in_onderzoek', 'datum_verkrijging_vreemd', 'voorletters_zdia', 'naam_zdia', 'voorv_mnaam_zdia', 'voorv_naam_zdia', 'meisjesnaam_zdia', 'nm_dia_255', 'mnm_dia_255'] in df personen!\n",
      "Missing values in df personen have been imputed!\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Clean personen dataset ##\n",
    "############################\n",
    "\n",
    "personenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=personenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['geboortedatum'],\n",
    "        lower_string_columns=True)\n",
    "    )])\n",
    "\n",
    "personen = personenPipeline.fit_transform(personenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"bag\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'postcode', 'type', 'adres_nummer', 'vervallen_nummeraanduiding', 'hoofdadres', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'vervallen_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'vervallen_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_mutatie', 'document_nummer', 'begin_geldigheid', 'einde_geldigheid'] in df bag!\n",
      "Missing values in df bag have been imputed!\n",
      "Missing values (using mode) of cols ['status_coordinaat_code'] in df bag have been imputed!\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "## Clean BAG dataset & perform feature extraction ##\n",
    "####################################################\n",
    "\n",
    "bagPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=bagDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=[],\n",
    "        drop_columns = ['indicatie_geconstateerd', 'indicatie_in_onderzoek', 'woningvoorraad'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_mode=['status_coordinaat_code'],\n",
    "#         impute_missing_values_mode=['status_coordinaat_code', 'indicatie_geconstateerd',\n",
    "#                                     'indicatie_in_onderzoek', 'woningvoorraad'],\n",
    "        fillna_columns={'_huisnummer_verblijfsobject': 0,\n",
    "                         '_huisletter_verblijfsobject': 'None',\n",
    "                         '_openbare_ruimte_naam_verblijfsobject': 'None',\n",
    "                         '_huisnummer_toevoeging_verblijfsobject': 'None',\n",
    "                         'type_woonobject_omschrijving': 'None',\n",
    "                         'eigendomsverhouding_id': 'None',\n",
    "                         'financieringswijze_id': -1,\n",
    "                         'gebruik_id': -1,\n",
    "                         'reden_opvoer_id': -1,\n",
    "                         'status_id_verblijfsobject': -1,\n",
    "                         'toegang_id': 'None'})\n",
    "    ),\n",
    "#     ('extract', FeatureExtractionTransformer(\n",
    "#         categorical_cols_hot=['status_coordinaat_code', 'type_woonobject_omschrijving',\n",
    "#                               'eigendomsverhouding_id', 'financieringswijze_id',\n",
    "#                               'gebruik_id', 'ligging_id', 'reden_opvoer_id',\n",
    "#                               'status_id_nummeraanduiding', 'toegang_id'])\n",
    "#     )\n",
    "    ])\n",
    "\n",
    "bagDataset.data = bagPipeline.fit_transform(bagDataset.data)\n",
    "bag = bagDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"hotline\": Dropped 0 duplicates!\n",
      "Lowered strings of cols ['mdw_code', 'overtreding_code', 'melder_anoniem', 'melder_naam', 'melder_emailadres', 'melder_telnr', 'situatie_schets', 'user_created', 'user_modified'] in df hotline!\n",
      "Missing values in df hotline have been imputed!\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Clean hotline dataset ##\n",
    "###########################\n",
    "\n",
    "hotlinePipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=hotlineDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "hotlineDataset.data = hotlinePipeline.fit_transform(hotlineDataset.data)\n",
    "hotline = hotlineDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"adres\": Dropped 0 duplicates!\n",
      "Dataframe \"adres\": Fixed dates!\n",
      "Lowered strings of cols ['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'hvv_dag_tek', 'max_vestig_dtm'] in df adres!\n",
      "Missing values in df adres have been imputed!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Clean adres dataset ##\n",
    "#########################\n",
    "\n",
    "# Hier de extract stap weghalen? Deze past waarschijnlijk beter na het combinen v/d datasets.\n",
    "adresPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=adresDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['hvv_dag_tek', 'max_vestig_dtm', 'wzs_update_datumtijd'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        fillna_columns={'hsnr': 0, 'sttnaam': 'None', 'hsltr': 'None', 'toev': 'None'})\n",
    "    )\n",
    "])\n",
    "#     ,\n",
    "#     ('extract', FeatureExtractionTransformer(\n",
    "#         categorical_cols_hot=['toev', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr'],\n",
    "#         ))\n",
    "#     ])\n",
    "\n",
    "adresDataset.data = adresPipeline.fit_transform(adresDataset.data)\n",
    "adres = adresDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df adres have been imputed!\n",
      "Saving version 'download_leegstand_woningId_bag' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/generic.py:2378: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_nummer']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adres dataset is now enriched with BAG data.\n",
      "Now looping over all address ids that have a link with one or more inhabitants...\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "Now looping over all rows in the adres dataframe in order to add person information...\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "...done!\n",
      "Saving version 'download_leegstand_woningId_bag_personen' of dataframe 'adres'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/generic.py:2378: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block5_values] [items->['postcode', 'sdl_code', 'brt_code', 'pvh_cd', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr', 'wzs_buurtcode_os_2015', 'wzs_buurtnaam_os_2015', 'wzs_buurtcombinatiecode_os_2015', 'wzs_buurtcombinatienaam_os_2015', 'wzs_22gebiedencode_os_2015', 'wzs_22gebiedennaam_os_2015', 'wzs_rayoncode_os_2015', 'wzs_rayonnaam_os_2015', 'wzs_stadsdeelcode_os_2015', 'wzs_stadsdeelnaam_os_2015', 'wzs_alternatieve_buurtennaam_os_2015', 'wzs_alternatieve_buurtencode_os_2015', 'wzs_geom', 'wzs_wijze_verrijking_geo', 'wzs_22gebiedencode_2015', 'wzs_22gebiedennaam_2015', 'sttnaam', 'hsltr', 'toev', 'brtcombi_naam', 'sdl_naam', 'brt_naam', 'a_dam_bag', 'landelijk_bag', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', '_openbare_ruimte_naam_nummeraanduiding', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'status_id_nummeraanduiding', 'verblijfsobject_id', '_geom', 'id_ligplaats', 'landelijk_id_ligplaats', 'geometrie_ligplaats', 'bron_id_ligplaats', 'status_id_ligplaats', 'id_standplaats', 'landelijk_id_standplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'id_verblijfsobject', 'landelijk_id_verblijfsobject', 'status_coordinaat_code', 'status_coordinaat_omschrijving', 'type_woonobject_code', 'type_woonobject_omschrijving', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'bron_id_verblijfsobject', 'eigendomsverhouding_id', 'financieringswijze_id', 'gebruik_id', 'ligging_id', 'locatie_ingang_id', 'reden_afvoer_id', 'reden_opvoer_id', 'status_id_verblijfsobject', 'toegang_id', '_gebiedsgerichtwerken_id', '_grootstedelijkgebied_id', 'buurt_id', 'document_nummer']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adres dataset is now enriched with personen data.\n",
      "Saving version 'download_leegstand_woningId_bag_personen_hotline' of dataframe 'adres'.\n",
      "The adres dataset is now enriched with hotline data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 16079 finished cases from a total of 31051 cases.\n",
      "Saving version 'download_categories_filterCategories_finishedCases' of dataframe 'zaken'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/generic.py:2378: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['afg_code_afs', 'afg_code_beh', 'afs_code', 'afs_oms', 'beh_code', 'beh_oms', 'categorie', 'eigenaar', 'mededelingen', 'zaak_id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \"zaken\": added column \"woonfraude\" (binary label)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "## Enrich adres dataset ##\n",
    "##########################\n",
    "\n",
    "# Enrich the adres dataset with information from the bag, personen and hotline datasets.\n",
    "adresDataset.enrich_with_bag(bagDataset.data)\n",
    "adresDataset.enrich_with_personen_features(personenDataset.data)\n",
    "adresDataset.add_hotline_features(hotlineDataset.data)\n",
    "\n",
    "\n",
    "##########################\n",
    "## Enrich zaken dataset ##\n",
    "##########################\n",
    "\n",
    "# Only keep the finished cases in the zaken dataset (remove all unfinished cases).\n",
    "zakenDataset.keep_finished_cases(stadiaDataset.data)\n",
    "\n",
    "# Add a label to indicate woonfraude.\n",
    "zakenDataset.add_binary_label_zaken(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Remove implicit label columns and superfluous columns  from adres dataset ##\n",
    "###############################################################################\n",
    "\n",
    "adres_remove = [# Remove because cols do not exists when melding is received\n",
    "                    'wzs_update_datumtijd',\n",
    "                    # Remove because cols do not add extra information.\n",
    "                    'kmrs',\n",
    "                    'straatcode',\n",
    "                    'xref',\n",
    "                    'yref',\n",
    "                    'postcode',\n",
    "                    'wzs_buurtcode_os_2015',\n",
    "                    'wzs_buurtcombinatiecode_os_2015',\n",
    "                    'wzs_stadsdeelcode_os_2015',\n",
    "                    'sttnaam',\n",
    "                    'hvv_dag_tek', # Empty column\n",
    "                    'max_vestig_dtm', # Empty column\n",
    "                    'wzs_22gebiedencode_os_2015', # Empty column\n",
    "                    'wzs_22gebiedennaam_os_2015', # Empty column\n",
    "                    'sdl_naam',\n",
    "                    'pvh_cd',\n",
    "                    'sbv_code',\n",
    "                    'sbw_code',\n",
    "                    'wzs_wijze_verrijking_geo',\n",
    "                    'wzs_22gebiedencode_2015',\n",
    "                    'brt_naam',\n",
    "                    'wzs_buurtnaam_os_2015',\n",
    "                    'wzs_buurtcombinatienaam_os_2015',\n",
    "                    'wzs_rayonnaam_os_2015',\n",
    "                    'wzs_rayoncode_os_2015',\n",
    "                    'wzs_stadsdeelnaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtennaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtencode_os_2015',\n",
    "                    'hsltr',\n",
    "                    'wzs_geom',\n",
    "                    'brt_code',\n",
    "                    'brtcombi_code',\n",
    "                    'brtcombi_naam',\n",
    "                    'sdl_code',\n",
    "                    'wzs_22gebiedennaam_2015',\n",
    "                    'wzs_id',\n",
    "                    'a_dam_bag',\n",
    "                    'landelijk_bag']\n",
    "\n",
    "bag_remove = ['einde_geldigheid',               # Only 2 entries in column.\n",
    "              'verhuurbare_eenheden',           # Only ~2k entries in column.\n",
    "              'geometrie_ligplaats',            # Needs a lot of processing before being useful.\n",
    "#               'bron_id',                      # Only 2 entries in column.\n",
    "              'bron_id_verblijfsobject',        # Only 2 entries in column.\n",
    "              'locatie_ingang_id',              # Only 2 entries in column.\n",
    "              'reden_afvoer_id',                # Only a few entries in column.\n",
    "              '_gebiedsgerichtwerken_id',       # Superfluous (gebied).\n",
    "              '_grootstedelijkgebied_id',       # Superfluous (grootstedelijkgebied).\n",
    "              'buurt_id',                       # Superfluous (buurt).\n",
    "              # ONDERSTAANDE 4 KOLOMMEN KONDEN EERDER NIET WEG IVM MATCH MET ADRES DATAFRAME.\n",
    "              # DEZE MOETEN NU WEL WEG, DAAROM WORDT NU HIER ALLES WEGGEHAALD.\n",
    "              '_openbare_ruimte_naam_nummeraanduiding',          # Superfluous (straatnaam).\n",
    "#               '_huisnummer_nummeraanduiding',                    # Superfluous (huisnummer).\n",
    "#               '_huisletter_nummeraanduiding',                    # Superfluous (huisletter).\n",
    "#               '_huisnummer_toevoeging_nummeraanduiding',         # Superfluous (huisnummer toevoeging).\n",
    "#               'vervallen',                      # Superfluous (all values in col are equal).\n",
    "              'vervallen_nummeraanduiding',\n",
    "              'vervallen_ligplaats',\n",
    "              'vervallen_standplaats',\n",
    "              'vervallen_verblijfsobject',\n",
    "              'document_mutatie',               # Not available at time of signal.\n",
    "#               'date_modified',                  # Not available at time of signal.\n",
    "              'date_modified_nummeraanduiding', # Not available at time of signal.\n",
    "              'document_nummer',                # Not needed? (Swaan?)\n",
    "              'status_coordinaat_omschrijving', # Not needed? (Swaan?)\n",
    "              'type_woonobject_code',           # Not needed? (Swaan?)\n",
    "              'id_ligplaats',                   # Not needed.\n",
    "              'landelijk_id_ligplaats',         # Not needed.\n",
    "              'id_standplaats',                 # Not needed.\n",
    "              'landelijk_id_standplaats',       # Not needed.\n",
    "              'id_verblijfsobject',             # Not needed.\n",
    "              'landelijk_id_verblijfsobject',   # Not needed.\n",
    "              ]\n",
    "\n",
    "# Remove adres_id, since this is not a feature we want our algorihtm to try and learn from.\n",
    "# adresDataset.data.drop(columns=adres_remove + bag_remove + ['adres_id'], inplace=True)\n",
    "adresDataset.data.drop(columns=adres_remove + bag_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Merge the adres dataset onto the zaken dataset ##\n",
    "####################################################\n",
    "\n",
    "# # Remove all unfinished cases in the zaken dataset.\n",
    "# zakenDataset.keep_finished_cases(stadiaDataset.data)\n",
    "\n",
    "# Merge the adres dataset onto the zaken dataset.\n",
    "zakenDataset.data = zakenDataset.data.merge(adresDataset.data, on='adres_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adres_id</th>\n",
       "      <th>afg_code_afs</th>\n",
       "      <th>afg_code_beh</th>\n",
       "      <th>afs_code</th>\n",
       "      <th>afs_oms</th>\n",
       "      <th>bedrag_huur</th>\n",
       "      <th>begindatum</th>\n",
       "      <th>beh_code</th>\n",
       "      <th>beh_oms</th>\n",
       "      <th>categorie</th>\n",
       "      <th>...</th>\n",
       "      <th>percentage_gezinsverhouding_3</th>\n",
       "      <th>gezinsverhouding_4</th>\n",
       "      <th>percentage_gezinsverhouding_4</th>\n",
       "      <th>gezinsverhouding_5</th>\n",
       "      <th>percentage_gezinsverhouding_5</th>\n",
       "      <th>gezinsverhouding_6</th>\n",
       "      <th>percentage_gezinsverhouding_6</th>\n",
       "      <th>gezinsverhouding_7</th>\n",
       "      <th>percentage_gezinsverhouding_7</th>\n",
       "      <th>aantal_hotline_meldingen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44312.0</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>pwibg</td>\n",
       "      <td>zl woning is beschikbaar gekomen</td>\n",
       "      <td>466.845141</td>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>zkl_dr_pm</td>\n",
       "      <td>zkl doorzon prostitutie/mensenhandel</td>\n",
       "      <td>prostitutie</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889860.0</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>pwibg</td>\n",
       "      <td>zl woning is beschikbaar gekomen</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>zkl_dr_drg</td>\n",
       "      <td>zkl doorzon drugs</td>\n",
       "      <td>drugs</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320561.0</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>pgwg</td>\n",
       "      <td>zl geen woonfraude</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>zkl_dr_ol</td>\n",
       "      <td>zkl doorzon onderhuur/leegstand</td>\n",
       "      <td>illegale onderhuur</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230853.0</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>pwibg</td>\n",
       "      <td>zl woning is beschikbaar gekomen</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>zkl_dr_hos</td>\n",
       "      <td>zkl doorzon illegaal hotel/shortstay</td>\n",
       "      <td>illegale hotels</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307169.0</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>vtbd</td>\n",
       "      <td>pgwg</td>\n",
       "      <td>zl geen woonfraude</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>2013-09-27</td>\n",
       "      <td>zkl_dr_pm</td>\n",
       "      <td>zkl doorzon prostitutie/mensenhandel</td>\n",
       "      <td>prostitutie</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    adres_id afg_code_afs afg_code_beh afs_code  \\\n",
       "0    44312.0         vtbd         vtbd    pwibg   \n",
       "1  1889860.0         vtbd         vtbd    pwibg   \n",
       "2   320561.0         vtbd         vtbd     pgwg   \n",
       "3   230853.0         vtbd         vtbd    pwibg   \n",
       "4   307169.0         vtbd         vtbd     pgwg   \n",
       "\n",
       "                            afs_oms  bedrag_huur begindatum    beh_code  \\\n",
       "0  zl woning is beschikbaar gekomen   466.845141 2012-09-25   zkl_dr_pm   \n",
       "1  zl woning is beschikbaar gekomen   750.000000 2014-03-05  zkl_dr_drg   \n",
       "2                zl geen woonfraude   546.000000 2013-01-14   zkl_dr_ol   \n",
       "3  zl woning is beschikbaar gekomen   757.000000 2014-01-15  zkl_dr_hos   \n",
       "4                zl geen woonfraude   465.000000 2013-09-27   zkl_dr_pm   \n",
       "\n",
       "                                beh_oms           categorie  ...  \\\n",
       "0  zkl doorzon prostitutie/mensenhandel         prostitutie  ...   \n",
       "1                     zkl doorzon drugs               drugs  ...   \n",
       "2       zkl doorzon onderhuur/leegstand  illegale onderhuur  ...   \n",
       "3  zkl doorzon illegaal hotel/shortstay     illegale hotels  ...   \n",
       "4  zkl doorzon prostitutie/mensenhandel         prostitutie  ...   \n",
       "\n",
       "  percentage_gezinsverhouding_3 gezinsverhouding_4  \\\n",
       "0                           0.0                  0   \n",
       "1                           0.0                  0   \n",
       "2                           0.5                  0   \n",
       "3                           0.0                  0   \n",
       "4                           0.2                  0   \n",
       "\n",
       "   percentage_gezinsverhouding_4 gezinsverhouding_5  \\\n",
       "0                            0.0                  0   \n",
       "1                            0.0                  2   \n",
       "2                            0.0                  0   \n",
       "3                            0.0                  0   \n",
       "4                            0.0                  0   \n",
       "\n",
       "   percentage_gezinsverhouding_5  gezinsverhouding_6  \\\n",
       "0                            0.0                   4   \n",
       "1                            0.5                   0   \n",
       "2                            0.0                   1   \n",
       "3                            0.0                   4   \n",
       "4                            0.0                   2   \n",
       "\n",
       "   percentage_gezinsverhouding_6  gezinsverhouding_7  \\\n",
       "0                            1.0                   0   \n",
       "1                            0.0                   0   \n",
       "2                            0.5                   0   \n",
       "3                            1.0                   0   \n",
       "4                            0.4                   0   \n",
       "\n",
       "  percentage_gezinsverhouding_7 aantal_hotline_meldingen  \n",
       "0                           0.0                        0  \n",
       "1                           0.0                        0  \n",
       "2                           0.0                        0  \n",
       "3                           0.0                        2  \n",
       "4                           0.0                        0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Als deze head zonder errors hierboven geprint wordt, dan werkt alles tot nu toe mooi.\n",
    "zakenDataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now extracting features from column: 'afg_code_beh'.\n",
      "Done!\n",
      "Now extracting features from column: 'beh_code'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigenaar'.\n",
      "Done!\n",
      "Now extracting features from column: 'categorie'.\n",
      "Done!\n",
      "Now extracting features from column: 'toev'.\n",
      "Done!\n",
      "Now extracting features from column: 'pvh_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbw_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'sbv_omschr'.\n",
      "Done!\n",
      "Now extracting features from column: 'status_coordinaat_code'.\n",
      "Done!\n",
      "Now extracting features from column: 'type_woonobject_omschrijving'.\n",
      "Done!\n",
      "Now extracting features from column: 'eigendomsverhouding_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'financieringswijze_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'gebruik_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'ligging_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'reden_opvoer_id'.\n",
      "Done!\n",
      "Now extracting features from column: 'status_id_nummeraanduiding'.\n",
      "Done!\n",
      "Now extracting features from column: 'toegang_id'.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "## Perform feature extraction on zaken dataset ##\n",
    "#################################################\n",
    "\n",
    "categorical_col_hot_zaken = ['afg_code_beh', 'beh_code', 'eigenaar', 'categorie']\n",
    "categorical_cols_hot_adres = ['toev', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr']\n",
    "categorical_cols_hot_bag = ['status_coordinaat_code', 'type_woonobject_omschrijving',\n",
    "                            'eigendomsverhouding_id', 'financieringswijze_id',\n",
    "                            'gebruik_id', 'ligging_id', 'reden_opvoer_id',\n",
    "                            'status_id_nummeraanduiding', 'toegang_id']\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=categorical_col_hot_zaken + categorical_cols_hot_adres + categorical_cols_hot_bag,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "zakenDataset.data = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load Finalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving version 'final' of dataframe 'zaken'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjongstra/.local/lib/python3.6/site-packages/pandas/core/generic.py:2378: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->['afg_code_afs', 'afs_code', 'afs_oms', 'beh_oms', 'mededelingen', 'zaak_id', 'postcode_x', 'id_nummeraanduiding', 'landelijk_id_nummeraanduiding', 'huisletter_nummeraanduiding', 'huisnummer_toevoeging_nummeraanduiding', 'type', 'adres_nummer', 'bron_id_nummeraanduiding', 'ligplaats_id', 'openbare_ruimte_id', 'standplaats_id', 'verblijfsobject_id', '_geom', 'bron_id_ligplaats', 'status_id_ligplaats', 'geometrie_standplaats', 'bron_id_standplaats', 'status_id_standplaats', 'geometrie_verblijfsobject', '_huisletter_verblijfsobject', 'status_id_verblijfsobject']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Save.\n",
    "zakenDataset.version = 'final'\n",
    "zakenDataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'final' of dataset 'zaken' loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load.\n",
    "zakenDataset = ZakenDataset()\n",
    "zakenDataset.load('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 16079\n",
      "Percentage positives: 53.3%\n"
     ]
    }
   ],
   "source": [
    "# Show percentage of positive samples in dataset.\n",
    "print(f\"Number of entries: {len(zakenDataset.data)}\")\n",
    "print(f\"Percentage positives: {round((zakenDataset.data.woonfraude.sum() * 100) / len(zakenDataset.data.woonfraude), 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the adres_id column.\n",
    "zakenDataset.data.drop(columns=['adres_id'], inplace=True)\n",
    "\n",
    "# Remove text columns, which can't be used for training.\n",
    "zakenDataset.data.drop(columns=['afg_code_afs', 'afs_code', 'afs_oms', 'beh_oms', 'mededelingen'], inplace=True)\n",
    "\n",
    "# Only keep numeric data columns.\n",
    "zakenDataset.data = zakenDataset.data._get_numeric_data()\n",
    "\n",
    "# Remove columns containing only NaN values.\n",
    "zakenDataset.data.drop(columns=['hoofdadres', 'begin_geldigheid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({True: 8572, False: 7507})\n",
      "Training set shape Counter({True: 7286, False: 6381})\n",
      "Testing set shape Counter({True: 1286, False: 1126})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split up the dataset (only use numeric data!).\n",
    "X_train, X_test, y_train, y_test = split_data_train_test(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores.\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters and distributions to sample from.\n",
    "param_dist = {\n",
    "              \"n_estimators\": sp_randint(100, 2000),\n",
    "#               \"max_features\": ['auto'],\n",
    "              \"max_features\": sp_randint(1, 100),\n",
    "              \"max_depth\": sp_randint(1, 100),\n",
    "              \"min_samples_leaf\": [1],\n",
    "              \"min_samples_split\": sp_randint(2, 5),\n",
    "              \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 16673.81831240654 seconds for 100 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.767 (std: 0.006)\n",
      "Parameters: {'bootstrap': False, 'max_depth': 16, 'max_features': 74, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1970}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.766 (std: 0.007)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 21, 'max_features': 61, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 483}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.766 (std: 0.006)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 34, 'max_features': 58, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1500}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.766 (std: 0.004)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 34, 'max_features': 57, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1554}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.766 (std: 0.006)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 32, 'max_features': 97, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 469}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.765 (std: 0.005)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 59, 'max_features': 83, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1480}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.765 (std: 0.008)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 38, 'max_features': 43, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1201}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.765 (std: 0.006)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 51, 'max_features': 97, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1911}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.765 (std: 0.005)\n",
      "Parameters: {'bootstrap': True, 'max_depth': 49, 'max_features': 56, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1511}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.765 (std: 0.005)\n",
      "Parameters: {'bootstrap': False, 'max_depth': 27, 'max_features': 78, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 873}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run randomized search.\n",
    "clf = RandomForestClassifier()\n",
    "n_iter = 100\n",
    "random_search = RandomizedSearchCV(clf,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1,\n",
    "                                   scoring='f1')\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print results.\n",
    "print(f\"RandomizedSearchCV took {time.time() - start} seconds for {len(random_search.cv_results_['params'])} candidate parameter settings.\")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model for later reuse in dashboard. Manually put this model in the \"data\" folder (temporary solution).\n",
    "best_random_forest_classifier_temp = random_search.best_estimator_\n",
    "pickle.dump(best_random_forest_classifier_temp, open(\"best_random_forest_classifier_temp.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
