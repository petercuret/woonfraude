{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Prepare Notebook\n",
    "\n",
    "Deze notebook wordt gebruikt om alle data uit de datasets in te laden en verder te verwerken, zodat deze klaar staat om modellen te trainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load public modules.\n",
    "import os, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Load environment variables.\n",
    "MAIN_PATH = os.getenv(\"WOONFRAUDE_PATH\")\n",
    "DATA_PATH = os.getenv(\"WOONFRAUDE_DATA_PATH\")\n",
    "CODEBASE_PATH = os.path.abspath(os.path.join(MAIN_PATH, 'codebase'))\n",
    "NOTEBOOK_PATH = os.path.abspath(os.path.join(MAIN_PATH, 'notebooks'))\n",
    "DASHBOARD_PATH = os.path.abspath(os.path.join(MAIN_PATH, 'dashboard'))\n",
    "\n",
    "# Add system paths.\n",
    "sys.path.insert(1, CODEBASE_PATH)\n",
    "\n",
    "# Import own modules.\n",
    "from datasets import *\n",
    "from clean import *\n",
    "from extract_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables.\n",
    "FORCE_DOWNLOAD = False\n",
    "FORCE_DATASET_SPECIFIC_PREPROCESSING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all datasets in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Initialize dataset objects #\n",
    "##############################\n",
    "\n",
    "adresDataset = AdresDataset()\n",
    "zakenDataset = ZakenDataset()\n",
    "stadiaDataset = StadiaDataset()\n",
    "personenDataset = PersonenDataset()\n",
    "bagDataset = BagDataset()\n",
    "hotlineDataset = HotlineDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Download data and perform dataset-specific pre-processing steps for dataset objects #\n",
    "#######################################################################################\n",
    "\n",
    "# Forces the downloading of new data.\n",
    "if FORCE_DOWNLOAD:\n",
    "    adresDataset.download(force=True)\n",
    "    zakenDataset.download(force=True)\n",
    "    stadiaDataset.download(force=True)\n",
    "    personenDataset.download(force=True)\n",
    "    bagDataset.download(force=True)\n",
    "    hotlineDataset.download(force=True)\n",
    "\n",
    "\n",
    "# Forces the dataset specific pre-processing of the downloaded data.\n",
    "if FORCE_DATASET_SPECIFIC_PREPROCESSING:\n",
    "    \n",
    "    # Adres dataset.\n",
    "    adresDataset.load('download')\n",
    "    adresDataset.extract_leegstand()\n",
    "    adresDataset.enrich_with_woning_id()\n",
    "\n",
    "    # Zaken Dataset.\n",
    "    zakenDataset.load('download')\n",
    "    zakenDataset.add_categories()\n",
    "    zakenDataset.filter_categories()  # Verwijder meldingen met categorieeen \"woningkwaliteit\" en \"afdeling vergunningen en beheer\".\n",
    "\n",
    "    # Stadia dataset.\n",
    "    stadiaDataset.load('download')\n",
    "    stadiaDataset.add_zaak_stadium_ids()\n",
    "\n",
    "    # Bag dataset.\n",
    "    bagDataset.load('download')\n",
    "    bagDataset.bag_fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "## Load datasets ##\n",
    "###################\n",
    "# Load datasets from cache (when download and pre-processing steps in previous block have been done).\n",
    "\n",
    "adresDataset.load('download_leegstand_woningId')\n",
    "zakenDataset.load('download_categories_filterCategories')\n",
    "stadiaDataset.load('download_ids')\n",
    "personenDataset.load('download')\n",
    "bagDataset.load('download_columnFix')\n",
    "hotlineDataset.load('download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and extract features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## Clean zaken dataset ##\n",
    "#########################\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=zakenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum','einddatum', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_custom={'categorie': 'missing'})\n",
    "    )])\n",
    "\n",
    "zaken = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Clean stadia dataset ##\n",
    "##########################\n",
    "\n",
    "stadiaPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=stadiaDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['begindatum', 'peildatum', 'einddatum', 'date_created',\n",
    "                          'date_modified', 'wzs_update_datumtijd'],\n",
    "        clean_dates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "stadia = stadiaPipeline.fit_transform(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Clean personen dataset ##\n",
    "############################\n",
    "\n",
    "personenPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=personenDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['geboortedatum'],\n",
    "        lower_string_columns=True)\n",
    "    )])\n",
    "\n",
    "personen = personenPipeline.fit_transform(personenDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "## Clean BAG dataset ##\n",
    "#######################\n",
    "\n",
    "bagPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=bagDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=[],\n",
    "        drop_columns = ['indicatie_geconstateerd', 'indicatie_in_onderzoek', 'woningvoorraad'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        impute_missing_values_mode=['status_coordinaat_code'],\n",
    "        fillna_columns={'_huisnummer_verblijfsobject': 0,\n",
    "                         '_huisletter_verblijfsobject': 'None',\n",
    "                         '_openbare_ruimte_naam_verblijfsobject': 'None',\n",
    "                         '_huisnummer_toevoeging_verblijfsobject': 'None',\n",
    "                         'type_woonobject_omschrijving': 'None',\n",
    "                         'eigendomsverhouding_id': 'None',\n",
    "                         'financieringswijze_id': -1,\n",
    "                         'gebruik_id': -1,\n",
    "                         'reden_opvoer_id': -1,\n",
    "                         'status_id_verblijfsobject': -1,\n",
    "                         'toegang_id': 'None'})\n",
    "    )])\n",
    "\n",
    "bagDataset.data = bagPipeline.fit_transform(bagDataset.data)\n",
    "bag = bagDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Clean hotline dataset ##\n",
    "###########################\n",
    "\n",
    "hotlinePipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=hotlineDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True)\n",
    "    )])\n",
    "\n",
    "hotlineDataset.data = hotlinePipeline.fit_transform(hotlineDataset.data)\n",
    "hotline = hotlineDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## Clean adres dataset ##\n",
    "#########################\n",
    "\n",
    "# Hier de extract stap weghalen? Deze past waarschijnlijk beter na het combinen v/d datasets.\n",
    "adresPipeline = Pipeline(steps=[\n",
    "    ('clean', CleanTransformer(\n",
    "        id_column=adresDataset.id_column,\n",
    "        drop_duplicates=True,\n",
    "        fix_date_columns=['hvv_dag_tek', 'max_vestig_dtm', 'wzs_update_datumtijd'],\n",
    "        lower_string_columns=True,\n",
    "        impute_missing_values=True,\n",
    "        fillna_columns={'hsnr': 0, 'sttnaam': 'None', 'hsltr': 'None', 'toev': 'None'})\n",
    "    )])\n",
    "\n",
    "adresDataset.data = adresPipeline.fit_transform(adresDataset.data)\n",
    "adres = adresDataset.data  # For easier usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "## Enrich adres dataset ##\n",
    "##########################\n",
    "\n",
    "# Enrich the adres dataset with information from the bag, personen and hotline datasets.\n",
    "adresDataset.enrich_with_bag(bagDataset.data)\n",
    "adresDataset.enrich_with_personen_features(personenDataset.data)\n",
    "adresDataset.add_hotline_features(hotlineDataset.data)\n",
    "\n",
    "\n",
    "##########################\n",
    "## Enrich zaken dataset ##\n",
    "##########################\n",
    "\n",
    "# Only keep the finished cases in the zaken dataset (remove all unfinished cases).\n",
    "zakenDataset.keep_finished_cases(stadiaDataset.data)\n",
    "\n",
    "# Add a label to indicate woonfraude.\n",
    "zakenDataset.add_binary_label_zaken(stadiaDataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Remove implicit label columns and superfluous columns  from adres dataset ##\n",
    "###############################################################################\n",
    "\n",
    "adres_remove = [# Remove because cols do not exists when melding is received\n",
    "                    'wzs_update_datumtijd',\n",
    "                    # Remove because cols do not add extra information.\n",
    "                    'kmrs',\n",
    "                    'straatcode',\n",
    "                    'xref',\n",
    "                    'yref',\n",
    "                    'postcode',\n",
    "                    'wzs_buurtcode_os_2015',\n",
    "                    'wzs_buurtcombinatiecode_os_2015',\n",
    "                    'wzs_stadsdeelcode_os_2015',\n",
    "                    'hvv_dag_tek', # Empty column\n",
    "                    'max_vestig_dtm', # Empty column\n",
    "                    'wzs_22gebiedencode_os_2015', # Empty column\n",
    "                    'wzs_22gebiedennaam_os_2015', # Empty column\n",
    "                    'pvh_cd',\n",
    "                    'sbv_code',\n",
    "                    'sbw_code',\n",
    "                    'wzs_wijze_verrijking_geo',\n",
    "                    'wzs_22gebiedencode_2015',\n",
    "                    'brt_naam',\n",
    "                    'wzs_buurtnaam_os_2015',\n",
    "                    'wzs_buurtcombinatienaam_os_2015',\n",
    "                    'wzs_rayonnaam_os_2015',\n",
    "                    'wzs_rayoncode_os_2015',\n",
    "                    'wzs_stadsdeelnaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtennaam_os_2015',\n",
    "                    'wzs_alternatieve_buurtencode_os_2015',\n",
    "                    'wzs_geom',\n",
    "                    'brt_code',\n",
    "                    'brtcombi_code',\n",
    "                    'brtcombi_naam',\n",
    "                    'sdl_code',\n",
    "                    'wzs_22gebiedennaam_2015',\n",
    "                    'wzs_id',\n",
    "                    'a_dam_bag',\n",
    "                    'landelijk_bag']\n",
    "\n",
    "bag_remove = ['einde_geldigheid',               # Only 2 entries in column.\n",
    "              'verhuurbare_eenheden',           # Only ~2k entries in column.\n",
    "              'geometrie_ligplaats',            # Needs a lot of processing before being useful.\n",
    "              'bron_id_verblijfsobject',        # Only 2 entries in column.\n",
    "              'locatie_ingang_id',              # Only 2 entries in column.\n",
    "              'reden_afvoer_id',                # Only a few entries in column.\n",
    "              '_gebiedsgerichtwerken_id',       # Superfluous (gebied).\n",
    "              '_grootstedelijkgebied_id',       # Superfluous (grootstedelijkgebied).\n",
    "              'buurt_id',                       # Superfluous (buurt).\n",
    "              # ONDERSTAANDE 4 KOLOMMEN KONDEN EERDER NIET WEG IVM MATCH MET ADRES DATAFRAME.\n",
    "              # DEZE MOETEN NU WEL WEG, DAAROM WORDT NU HIER ALLES WEGGEHAALD.\n",
    "              '_openbare_ruimte_naam_nummeraanduiding',          # Superfluous (straatnaam).\n",
    "              'vervallen_nummeraanduiding',\n",
    "              'vervallen_ligplaats',\n",
    "              'vervallen_standplaats',\n",
    "              'vervallen_verblijfsobject',\n",
    "              'document_mutatie',               # Not available at time of signal.\n",
    "              'date_modified_nummeraanduiding', # Not available at time of signal.\n",
    "              'document_nummer',                # Not needed? (Swaan?)\n",
    "              'status_coordinaat_omschrijving', # Not needed? (Swaan?)\n",
    "              'type_woonobject_code',           # Not needed? (Swaan?)\n",
    "              'id_ligplaats',                   # Not needed.\n",
    "              'landelijk_id_ligplaats',         # Not needed.\n",
    "              'id_standplaats',                 # Not needed.\n",
    "              'landelijk_id_standplaats',       # Not needed.\n",
    "              'id_verblijfsobject',             # Not needed.\n",
    "              'landelijk_id_verblijfsobject',   # Not needed.\n",
    "              ]\n",
    "\n",
    "# Remove the columns that are defined above from the dataset.\n",
    "adresDataset.data.drop(columns=adres_remove + bag_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Merge the adres dataset onto the zaken dataset ##\n",
    "####################################################\n",
    "\n",
    "# Merge the adres dataset onto the zaken dataset.\n",
    "zakenDataset.data = zakenDataset.data.merge(adresDataset.data, on='adres_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## Perform feature extraction on zaken dataset ##\n",
    "#################################################\n",
    "\n",
    "categorical_col_hot_zaken = ['afg_code_beh', 'beh_code', 'eigenaar', 'categorie']\n",
    "categorical_cols_hot_adres = ['toev', 'pvh_omschr', 'sbw_omschr', 'sbv_omschr']\n",
    "categorical_cols_hot_bag = ['status_coordinaat_code', 'type_woonobject_omschrijving',\n",
    "                            'eigendomsverhouding_id', 'financieringswijze_id',\n",
    "                            'gebruik_id', 'ligging_id', 'reden_opvoer_id',\n",
    "                            'status_id_nummeraanduiding', 'toegang_id']\n",
    "\n",
    "zakenPipeline = Pipeline(steps=[\n",
    "    ('extract', FeatureExtractionTransformer(\n",
    "        categorical_cols_hot=categorical_col_hot_zaken + categorical_cols_hot_adres + categorical_cols_hot_bag,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "zakenDataset.data = zakenPipeline.fit_transform(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Finalized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save.\n",
    "zakenDataset.version = 'final'\n",
    "zakenDataset.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
