{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Train Notebook\n",
    "\n",
    "Deze notebook wordt gebruikt om de data, die met de master_prepare notebook geprepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load public modules.\n",
    "import os, sys\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Get the home dir and username.\n",
    "HOME = Path.home()\n",
    "USERNAME = os.path.basename(HOME)\n",
    "\n",
    "# Set codebase path for old VAO.\n",
    "CODEBASE_PATH_OLD = os.path.join(HOME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_OLD)\n",
    "                \n",
    "# Set codebase path for new VAO.\n",
    "CODEBASE_PATH_NEW = os.path.join('/data', USERNAME, 'Documents/woonfraude/codebase/')\n",
    "sys.path.insert(1, CODEBASE_PATH_NEW)\n",
    "\n",
    "# Import own modules.\n",
    "from datasets import *\n",
    "from build_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load finalized dataset (from master_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 'final' of dataset 'zaken' loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "zakenDataset = ZakenDataset()\n",
    "zakenDataset.load('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 16079\n",
      "Percentage positives: 53.3%\n"
     ]
    }
   ],
   "source": [
    "# Show percentage of positive samples in dataset.\n",
    "print(f\"Number of entries: {len(zakenDataset.data)}\")\n",
    "print(f\"Percentage positives: {round((zakenDataset.data.woonfraude.sum() * 100) / len(zakenDataset.data.woonfraude), 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the adres_id column.\n",
    "zakenDataset.data.drop(columns=['adres_id'], inplace=True)\n",
    "\n",
    "# Remove text columns, which can't be used for training.\n",
    "zakenDataset.data.drop(columns=['afg_code_afs', 'afs_code', 'afs_oms', 'beh_oms', 'mededelingen'], inplace=True)\n",
    "\n",
    "# Only keep numeric data columns.\n",
    "zakenDataset.data = zakenDataset.data._get_numeric_data()\n",
    "\n",
    "# Remove columns containing only NaN values.\n",
    "zakenDataset.data.drop(columns=['hoofdadres', 'begin_geldigheid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({True: 8572, False: 7507})\n",
      "Training set shape Counter({True: 7286, False: 6381})\n",
      "Testing set shape Counter({True: 1286, False: 1126})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split up the dataset (only use numeric data!).\n",
    "X_train, X_test, y_train, y_test = split_data_train_test(zakenDataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores.\n",
    "def report(results, n_top=10):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters and distributions to sample from.\n",
    "param_dist = {\n",
    "              \"n_estimators\": sp_randint(100, 1000),\n",
    "#               \"max_features\": ['auto'],\n",
    "              \"max_features\": sp_randint(1, 100),\n",
    "              \"max_depth\": sp_randint(1, 100),\n",
    "              \"min_samples_leaf\": [1],\n",
    "              \"min_samples_split\": sp_randint(2, 5),\n",
    "              \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run randomized search with random forest *regressor*.\n",
    "\n",
    "# We currently use a scoring parameter that was chosen without too much thought.\n",
    "# We intend to run the search using different scoring parameters in the future,\n",
    "# and testing the performance in a binary fashion afterwards, by mapping percentages\n",
    "# below 50% to False and percentages above 50% to True.\n",
    "#\n",
    "# See this link for more information about the possible scoring parameters for regression:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    \n",
    "clf = RandomForestRegressor()\n",
    "n_iter = 10\n",
    "random_search = RandomizedSearchCV(clf,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter,\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   scoring='r2')\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print results.\n",
    "print(f\"RandomizedSearchCV took {time.time() - start} seconds for {len(random_search.cv_results_['params'])} candidate parameter settings.\")\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model for later reuse in dashboard. Manually put this model in the \"data\" folder (temporary solution).\n",
    "\n",
    "# Select best model.\n",
    "best_random_forest_regressor_temp = random_search.best_estimator_\n",
    "\n",
    "# Create feature list and add to model.\n",
    "feature_names = list(X_train.columns)\n",
    "best_random_forest_regressor_temp.feature_names = feature_names\n",
    "\n",
    "# Save model.\n",
    "pickle.dump(best_random_forest_regressor_temp, open(\"best_random_forest_regressor_temp.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
